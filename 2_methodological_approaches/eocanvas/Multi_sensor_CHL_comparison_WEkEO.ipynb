{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='https://gitlab.eumetsat.int/eumetlab/oceans/ocean-training/tools/frameworks/-/raw/main/img/Standard_banner.png' align='right' width='100%'/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"../../../Index.ipynb\" target=\"_blank\"><< Index</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"#138D75\">**Copernicus Marine Training Service**</font> <br>\n",
    "**Copyright:** 2025 European Union <br>\n",
    "**License:** MIT <br>\n",
    "**Authors:** Ben Loveday (EUMETSAT/Innoflair UG), Hayley Evers-King (EUMETSAT), Anna-Lena Erdmann (EUMETSAT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<html>\n",
    "   <div style=\"float:left\"><p>&emsp;</p></div>\n",
    "   <div style=\"float:left\"><a href=\"https://gitlab.eumetsat.int/eumetlab/oceans/ocean-training/applications/ocean-colour-applications\"><img src=\"https://img.shields.io/badge/open-EUMETLAB-E67E22.svg\"></a></div>\n",
    "   <div style=\"float:left\"><p>&emsp;</p></div>\n",
    "   <div style=\"float:left\"><a href=\"https://user.eumetsat.int/data/themes/marine\"><img src=\"https://img.shields.io/badge/open-USER PORTAL-154360.svg\"></a></div>\n",
    "   <div style=\"float:left\"><p>&emsp;</p></div>\n",
    "   <div style=\"float:left\"><a href=\"https://mybinder.org/v2/git/https%3A%2F%2Fgitlab.eumetsat.int%2Feumetlab%2Foceans%2Focean-training%2Fapplications%2Focean-colour-applications/HEAD?labpath=2_methodological_approaches%2Feocanvas%2FMulti_sensor_CHL_comparison_WEkEO.ipynb\"><img src=\"https://mybinder.org/badge_logo.svg\"></a></div>\n",
    "   <div style=\"float:left\"><p>&emsp;</p></div>\n",
    "   <div style=\"float:left\"><a href=\"https://jupyterhub.prod.wekeo2.eu/hub/user-redirect/lab/tree/public/wekeo4oceans/ocean-colour-applications/2_methodological_approaches/eocanvas/Multi_sensor_CHL_comparison_WEkEO.ipynb\"><img src=\"https://img.shields.io/badge/launch-WEKEO-1a4696.svg\"></a></div>\n",
    "</html>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<h3>Ocean colour applications</h3></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "    \n",
    "<b>PREREQUISITES </b>\n",
    "\n",
    "This notebook has the following prerequisites:\n",
    "- **<a href=\"https://my.wekeo.eu/user-registration\" target=\"_blank\">A WEkEO account</a>** to work with Copernicus Sentinel-3 OLCI marine data from EUMETSAT Data Store\n",
    "- **<a href=\"https://data.marine.copernicus.eu/register\" target=\"_blank\">A Copernicus Marine Service (CMEMS) account</a>** to work with data from the CMEMS Data Store\n",
    "    \n",
    "There are no prerequisite notebooks for this module, but you may wish to look at the following notebooks on using Sentinel-3 OLCI data; <br>\n",
    "- **<a href=\"https://gitlab.eumetsat.int/eumetlab/oceans/ocean-training/sensors/learn-olci\" target=\"_blank\">Learn OLCI (EUMETSAT Gitlab)</a>**\n",
    "\n",
    "</div>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-sensor chlorophyll comparison in the Baltic Sea using WEkEO serverless functions\n",
    "<font color=\"#138D75\">**Developed by EUMETSAT in support of the 2025 EGU General Assembly**</font>\n",
    "\n",
    "### Data used\n",
    "\n",
    "| Dataset | EUMETSAT collection ID | EUMETSAT collection<br>description | WEkEO dataset ID | WEkEO description | Copernicus Marine<br>Data Store product ID | Copernicus Marine<br>product description |\n",
    "|:--------------------:|:-----------------------:|:-------------:|:-----------------:|:-----------------:|:-----------------:|:-----------------:|\n",
    "| Sentinel-3 OLCI level-1b full resolution | EO:EUM:DAT:0409 | <a href=\"https://user.eumetsat.int/catalogue/EO:EUM:DAT:SENTINEL-3:OL_1_EFR___NTC\" target=\"_blank\">Description</a> | EO:EUM:DAT:SENTINEL-3:OL_1_EFR___ | <a href=\"https://www.wekeo.eu/data?view=dataset&dataset=EO%3AEUM%3ADAT%3ASENTINEL-3%3AOL_1_EFR___\" target=\"_blank\">Description</a> | - | - |\n",
    "| Sentinel-3 OLCI level-2 full resolution | EO:EUM:DAT:0407 | <a href=\"https://user.eumetsat.int/catalogue/EO:EUM:DAT:SENTINEL-3:OL_2_WFR___NTC\" target=\"_blank\">Description</a> | EO:EUM:DAT:SENTINEL-3:OL_2_WFR___ | <a href=\"https://www.wekeo.eu/data?view=dataset&dataset=EO%3AEUM%3ADAT%3ASENTINEL-3%3AOL_2_WFR___\" target=\"_blank\">Description</a> | - | - |\n",
    "| Baltic Sea Multiyear Ocean Colour Plankton, Reflectances and Transparency L3 daily observations | - | - | OCEANCOLOUR_BAL_BGC_L3_MY_009_133 | <a href=\"https://www.wekeo.eu/data?view=dataset&dataset=EO%3AMO%3ADAT%3AOCEANCOLOUR_BAL_BGC_L3_MY_009_133\" target=\"_blank\">Description</a> | OCEANCOLOUR_BAL_BGC_L3_MY_009_133 | <a href=\"https://data.marine.copernicus.eu/product/OCEANCOLOUR_BAL_BGC_L3_MY_009_133/description\" target=\"_blank\">Description</a> |\n",
    "\n",
    "### Learning outcomes\n",
    "\n",
    "At the end of this notebook you will know how to ;\n",
    "\n",
    "* access Sentinel-3 OLCI ocean colour data via WEkEO\n",
    "* compare and understand differences between data derived with different chlorophyll-a algorithms\n",
    "* process Sentinel-3 OLCI data sets using the WEkEO `eocanvas` serverless function architecture\n",
    "* create a data cube from these processed products, and visualise them in `xcube`\n",
    "* compare our outputs with regionally tuned ocean colour products from the Copernicus Marine Service\n",
    "* plot time series of ocean colour data to contextualise bloom events\n",
    "\n",
    "### Outline\n",
    "\n",
    "Whilst production by algae is an essential component of marine foodwebs and biogeochemical cycling, extreme blooms [[1]](#ref1) can also pose risks to environmental and human health. Eutrophication, excessive algal growth, as a result of excess nutrients from anthropogenic activities, is a long standing issue in the Baltic sea. Cyanobacteria play a central role in this issue. Whilst cyanobacteria blooms can occur naturally, particularly in warm weather, they can be exacerbated by nutrient inputs. They also play a feedback role in the nutrient loading due to their nitrogen fixing capabilities, and present additional hazards when they bloom. Blooms can affect fish stocks, aquaculture, bathing water quality and tourism, as well as causing rashes, respiratory, and gastrointestinal issues for those exposed.\n",
    "\n",
    "<figure>\n",
    "  <img src=\"https://www.researchgate.net/publication/315534680/figure/fig2/AS:614155694395429@1523437536804/Surface-accumulations-of-cyanobacteria-in-the-southern-Baltic-Sea-in-2013-Photo-credit.png\" width='40%'/>\n",
    "  <img src=\"https://gitlab.eumetsat.int/eumetlab/oceans/ocean-training/applications/ocean-case-studies/-/raw/main/img/Cyanobacteria_bloom.png\" width='51.25%'/>\n",
    "  <figcaption><a id='figure1'>Figure 1: Cyanobacteria can form bright green blooms that float on the surface (left), making them readily visible in optical measurements taken by satellites such as Sentinel-3A and B and their Ocean and Land Colour Instruments (OLCI) (right) (Credit: (left) <a href=\"https://tos.org/oceanography/article/globalhab-a-new-program-to-promote-international-research-observations-and\" target=\"blank\">Berdalet et al. (2017)</a>, CC-BY-4.0, (right) EUMETSAT). </figcaption>\n",
    "</figure>\n",
    "\n",
    "Satellite ocean colour can provide operational views of water quality, with the Ocean and Land Colour Imager (OLCI) sensor aboard the Copernicus Sentinel-3 mission, operated by EUMETSAT, particularly well suited to observing eutrophication and algal blooms such as those occurring in the Baltic Sea. However retreiving accurate geophysical information in these situations is not trivial, and products such a chlorophyll-a derived from a variety of algorithms, can be more/less suitable. \n",
    "\n",
    "In this notebook, we will take a variety of different approaches to exploring some Baltic cyanobacterial blooms, taking data from multiple sources. Single sensor approaches will use level-1b and level-2 OLCI ocean colour products, distributed by EUMETSAT and made available by on the <a href='https://wekeo.copernicus.eu/'>WEkEO</a> DIAS cloud platform. These data are distributed on the instrument grid, which changes in time, meaning that we will have to process each image in turn to eventually work with them all concert. We will use the WEkEO `eocanvas` serverless function capability to remotely call the ESA SNAP package to perform this processing. We will compare these products with the multi-sensor, level-3 Baltic chlorophyll product provided by the <a href=\"https://marine.copernicus.eu/\" target=\"_blank\">Copernicus Marine Service</a>. More specifically, we will look at the chlorophyll estimates retrieved using the following algorithms;\n",
    "\n",
    "| Algorithm | Data Source | Suitability |\n",
    "|:--------------------:|:-----------------------:|:-------------:|\n",
    "| NN | Included in OLCI level-2 products | Neural network based approach (NN) for complex waters |\n",
    "| OC4ME | Included in OLCI level-2 products | Algal pigment concentration in open waters | \n",
    "| MPH | Derived from OLCI level-1 products | Maximum Peak Height algorithm, suitable for cyanobacteria dominated waters |\n",
    "| MLP | Copernicus Marine Service level-3 Baltic chlorophyll product | Regionally developed for suitability to the Baltic region |\n",
    "\n",
    "#### References\n",
    "\n",
    "1. <a id='ref1'><a href=\"https://aslopubs.onlinelibrary.wiley.com/doi/10.4319/lo.1997.42.5_part_2.1132\" target=\"blank\">Smayda, T. J. (1997). What is a bloom? A commentary. Limnology and Oceanography, 42(5part2), 1132-1136.</a>\n",
    "2. <a id='ref2'><a href=\"https://www.sciencedirect.com/science/article/abs/pii/S0034425712002350\" target=\"blank\">Matthews, M. W., Bernard, S., & Robertson, L. (2012). An algorithm for detecting trophic status (chlorophyll-a), cyanobacterial-dominance, surface scums and floating vegetation in inland and coastal waters. Remote Sensing of Environment, 124, 637-652.</a>\n",
    "3. <a id='ref3'><a href=\"https://www.mdpi.com/2072-4292/13/16/3071\" target=\"_blank\">Brando, V. E., Sammartino, M., Colella, S., Bracaglia, M., Di Cicco, A., Dâ€™Alimonte, D., ... & Attila, J. (2021). Phytoplankton bloom dynamics in the baltic sea using a consistently reprocessed time series of multi-sensor reflectance and novel chlorophyll-a retrievals. Remote Sensing, 13(16), 3071.</a>\n",
    "\n",
    "<div class=\"alert alert-info\" role=\"alert\">\n",
    "\n",
    "## <a id='TOCTOP'></a>Contents\n",
    "\n",
    "</div>\n",
    "\n",
    " 1. [Step 1: Setting up our analysis](#section1)\n",
    " 1. [Step 2: Selecting our data using the WEkEO harmonised data access (HDA) adaptor](#section2)\n",
    " 1. [Step 3: Processing Copernicus Sentinel-3 OLCI data using WEkEO `eocanvas` serverless functions](#section3)\n",
    " 1. [Step 4: Building data cubes](#section4)\n",
    " 1. [Step 5: Comparing chlorophyll estimates using `xcube`](#section5)\n",
    " 1. [Step 6: Exploring level-3 ocean Baltic colour products from the Copernicus Marine Service](#section6)\n",
    " 1. [Step 7: Downloading and analysing level-3 ocean colour products](#section7)\n",
    " 1. [Step 8: Conclusions](#section8)\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\" role=\"alert\">\n",
    "\n",
    "## <a id='section1'></a>1. Setting up our analysis\n",
    "[Back to top](#TOCTOP)\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we will set up all the parameters we need to run our notebook.\n",
    "\n",
    "We will begin by importing all of the libraries that we need to run this notebook. If you have built your python using the environment file provided in this repository, then you should have everything you need. For more information on building environment, please see the repository **<a href=\"../../README.md\" target=\"_blank\">README</a>**.\n",
    "\n",
    "If you are running on WEkEO, you should ensure that you have selected the \"**miniwekeolab**\" environment/ipkernel using the menu option on the top right of the panel. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings                                      # a library that supports managing warning messages\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import os                                            # a library that allows us access to basic operating system commands\n",
    "import glob                                          # a library that helps us search for files\n",
    "import datetime                                      # a library that allows us to work with dates and times\n",
    "import xarray as xr                                  # a library that helps us work efficiently with multi-dimensional arrays\n",
    "import matplotlib.pyplot as plt                      # a library the provides plotting capability\n",
    "import numpy as np                                   # a library that lets us work with arrays; we import this with a new name \"np\"\n",
    "from pathlib import Path                             # a library that helps construct system path objects\n",
    "import getpass                                       # a library to help us enter passwords\n",
    "import copernicusmarine                              # a library to help us access CMEMS data\n",
    "from xcube.webapi.viewer import Viewer               # a library that provides the Xcube viewer\n",
    "from shapely import geometry                         # a library that supports the creation of shape objects, like polygons\n",
    "import hda                                           # a library that supports WEkEO harmonised data access \n",
    "import pandas as pd                                  # a library that supports time series analysis\n",
    "from eocanvas.api import Input, Config, ConfigOption # the eocanvas api\n",
    "from eocanvas.snap.graph import Graph                # the part of the eocanvas library for working with SNAP graphs\n",
    "from eocanvas.snap import Operator                   # the part of the eocanvas library for defining SNAP graphs nodes\n",
    "from eocanvas.processes import SnapProcess           # the part of the eocanvas library for defining SNAP processes\n",
    "\n",
    "# set Xcube server if running on WEkEO\n",
    "if \"WEKEO_DATABROKER_URL\" in os.environ:\n",
    "    os.environ[\"XCUBE_JUPYTER_LAB_URL\"] = f\"https://jupyterhub.prod.wekeo2.eu/user/{os.environ['JUPYTERHUB_USER']}/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section of the notebook we will define all the parameters that we need to select, process and download level-1b and level-2 OLCI products, from which we will process our single-sensor chlorophyll products. To find our data of interest, we need to define:\n",
    "\n",
    "* our region of interest (ROI), which we will also need as a well known text (WKT) format polygon\n",
    "* the time period over which we want to find data (we'll be looking over a period where we know a bloom occurred).\n",
    "\n",
    "Lets set these parameters, starting with a square box that we can turn into a WKT polygon for searching.\n",
    "\n",
    "*Note: our default example is for the Baltic sea in mid-2022, but you can adapt this for other regions and times as you like.*\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining our bounding box (W, S, E, N) and WKY polygon\n",
    "bbox = [17, 55.0, 20.0, 60.0]\n",
    "polygon = [[bbox[0], bbox[1]], [bbox[2], bbox[1]], [bbox[2], bbox[3]], [bbox[0], bbox[3]], [bbox[0], bbox[1]]]\n",
    "WKT = geometry.Polygon([[p[0], p[1]] for p in polygon])\n",
    "\n",
    "# defining our search times\n",
    "start_L2 = datetime.datetime(2022, 7, 3, 0, 0, 0)\n",
    "end_L2 = datetime.datetime(2022, 7, 4, 23, 59, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let us set our `collectionID`s, the references for each collection in the WEkEO catalog (for example; `EO:EUM:DAT:SENTINEL-3:OL_1_EFR___`). These can be found in the <a href=\"https://wekeo.copernicus.eu/data?view=catalogue\">WEkEO Data Catalog</a>. We will store these in a Python dictionary, as follows..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sources = {\n",
    "               \"L1B\" : {\"collectionID\" : \"EO:EUM:DAT:SENTINEL-3:OL_1_EFR___\"}, # this is the OLCI level-1b collection ID, which contains top of atmosphere radiances\n",
    "               \"L2\"  : {\"collectionID\" : \"EO:EUM:DAT:SENTINEL-3:OL_2_WFR___\"}, # this is the OLCI level-2 collection ID, which contains atmospherically corrected reflectances\n",
    "               }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, lets set a timeliness parameter so that we can select on non-time critical (NT) scenes, which are of a higher quality than near real time data. We will also define our satellites, to include only Sentinel-3B at this stage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "timeliness = \"NT\"\n",
    "satellite = \"Sentinel-3B\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, lets define a download directory, where we can download our products to;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "download_dir = os.path.join(os.getcwd(), \"products\")\n",
    "os.makedirs(download_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have set our parameters, we can search for some matching data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\" role=\"alert\">\n",
    "\n",
    "## <a id='section99'></a>Defining functions\n",
    "[Back to top](#TOCTOP)\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining a quick function to parse dates\n",
    "\n",
    "Before we move on to our analysis, we are going to define a quick function for use later on. We define functions when we have some code that we want to use repeatedly later on. In this section we define a quick functions that we will use to search by dates in a SAFE format filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_first_date(filename):\n",
    "    parts = filename.split('_')\n",
    "    for part in parts:\n",
    "        try:\n",
    "            return datetime.datetime.strptime(part, \"%Y%m%dT%H%M%S\")\n",
    "        except ValueError:\n",
    "            continue\n",
    "    return None  # fallback if no date found"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\" role=\"alert\">\n",
    "\n",
    "## <a id='section2'></a>2. Selecting our data using the WEkEO harmonised data access (HDA) adaptor\n",
    "[Back to top](#TOCTOP)\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "\n",
    "### Accessing data using the WEkEO HDA adaptor\n",
    "\n",
    "Downloading from WEkEO harmonised data access (HDA) API is facilitated by a data access client. If you are currently working on the WEkEO JupyterHub, this client will already be installed. Otherwise, if you have followed the installation guidelines in the yml file provided with this repository, you will also have the client installed. If not, you are welcome to view the <a href=\"https://github.com/ecmwf/hda\" target=\"_blank\">source code</a> for more information and further instructions.\n",
    "\n",
    "In order to allow us to download data using the WEkEO HDA API, we need to provide our credentials. To do this, we need to create a file called `.hdarc` in our home directory. For most computer systems the home directory can be found at the path \\user\\username, /users/username, or /home/username depending on your operating system. In this file we need to add the following information exactly as follows;\n",
    "\n",
    "`user:<your_user_name>`<br>\n",
    "`password:<your_password>`\n",
    "\n",
    "You must replace `<your_user_name>` and `<your_password>` with the information from your WEkEO account (if you don't have one yet, please register at <a href=\"https://www.wekeo.eu/\" target=\"_blank\">https://www.wekeo.eu/</a>. Once you have entered these credentials in the file, the `hda` client will automatically read in the credentials from the file when you use it.\n",
    "\n",
    "If you need help with creating this file, you can use our WEkEO HDA API section of our <a href=\"../../working-with-python/API_authentication.ipynb\">API helper notebook</a> to assist you.\n",
    "\n",
    "*Note: take care not to share your user name and password*\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our credentials set up we can set-up and instance of the HDA client, as below;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = hda.Client()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can loop through our data sources dictionary, using the search parameters we defined above to find the matching products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data_source in data_sources:\n",
    "\n",
    "    # need to check on auth here\n",
    "    query = {\n",
    "            \"dataset_id\": data_sources[data_source][\"collectionID\"],\n",
    "            \"dtstart\"   : start_L2.strftime(\"%Y-%m-%dT%H:%M:%S.000Z\"),\n",
    "            \"dtend\"     : end_L2.strftime(\"%Y-%m-%dT%H:%M:%S.000Z\"),\n",
    "            \"timeliness\": timeliness,\n",
    "            \"bbox\"      : bbox,\n",
    "            \"sat\"       : satellite\n",
    "            }\n",
    "    \n",
    "    results = c.search(query)\n",
    "    data_sources[data_source][\"results\"] = results\n",
    "    data_sources[data_source][\"urls\"] = results.get_download_urls()\n",
    "    data_sources[data_source][\"product_names\"] = [results.results[i][\"id\"] for i in range(len(results))]\n",
    "\n",
    "    print(f\"Found: {len(results)} products for {data_sources[data_source]['collectionID']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\" role=\"alert\">\n",
    "\n",
    "## <a id='section3'></a>3. Processing Copernicus Sentinel-3 OLCI data using WEkEO `eocanvas` serverless functions\n",
    "[Back to top](#TOCTOP)\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Should we wish, we could now directly download the entirety of the level-1b and level-2 products that come from our search, using the following command:\n",
    "\n",
    "`data_sources[\"L1B\"][\"results\"].download(download_dir=download_dir)`\n",
    "\n",
    "or\n",
    "\n",
    "`data_sources[\"L2\"][\"results\"].download(download_dir=download_dir)`\n",
    "\n",
    "However, OLCI level-1b and level-2 scenes are typically ~900 Mb and ~500 Mb in size, respectively. Furthermore, these are not yet fully processed for our needs and so it would be more efficient to process these results remotely, subsequently downloading only the final, much smaller products. This is what we will do.\n",
    "\n",
    "We are going to process our products using a <a href=\"https://step.esa.int/main/toolboxes/snap/\">ESA SNAP</a> software package. Access to this package is managed through the WEkEO `eocanvas` python library, which allows us to run SNAP as a serverless function. However, we need to provide instructions to SNAP in order to define the processes we want to perform. We achieve this by providing `eocanvas` an XML format \"Graph\" that SNAP can ingest using its command-line based Graph Processing Tool (GPT). Lets look at these graphs and then set-up our `eocanvas` process.\n",
    "\n",
    "We have included two example graphs in the `SNAP_graphs` folder, one for L2 processing, which we will focus on, and one for L1 processing. Lets load these into our `data_sources` dictionary using the `Graph` method from `eocanvas`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sources[\"L1B\"][\"graph\"] = Graph.from_uri(os.path.join(os.getcwd(), \"SNAP_graphs\", \"SNAP_GPT_graph_OLCI_L1B_subset_MphChl_reproject_eocanvas_template.xml\"))\n",
    "data_sources[\"L2\"][\"graph\"] = Graph.from_uri(os.path.join(os.getcwd(), \"SNAP_graphs\", \"SNAP_GPT_graph_OLCI_L2_subset_flag_reproject_chl_eocanvas_template.xml\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets take a look..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# show it\n",
    "data_sources[\"L2\"][\"graph\"].nice_view()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that a number of steps are defined, each contained within a single \"Node\". We have following nodes:\n",
    "\n",
    "* Read - where we read our inpur product\n",
    "* BandMathsNN - where we apply the relevant quality flags to our OLCI complex water chlorophyll product (CHL_NN) - parallel\n",
    "* BandMathsOC4ME- where we apply the relevant quality flags to our OLCI standard chlorophyll product (CHL_OC4ME) - parallel\n",
    "* Merge - where we merge the band maths products together\n",
    "* Reproject - where we place the products on a regular grid\n",
    "* Write - where we output for final product\n",
    "\n",
    "However, we can also see that one node has been deliberately commented out; \"subset\". This is intentional as we will now add it using `eocanvas`. We can do this using the `Operator` method to define new nodes, as follows;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data_source in data_sources:\n",
    "\n",
    "    # load the graph\n",
    "    graph = data_sources[data_source][\"graph\"]\n",
    "\n",
    "    # define a subset node\n",
    "    subset = Operator(\"Subset\")\n",
    "    subset.geoRegion = str(WKT)\n",
    "    subset.fullSwath = \"false\"\n",
    "    subset.copyMetadata = \"false\"\n",
    "\n",
    "    # define subset bands, if required\n",
    "    if \"L2\" in data_source:\n",
    "        subset.bandNames = \"CHL_NN,CHL_OC4ME,latitude,longitude,WQSF_lsb,WQSF_msb\"\n",
    "\n",
    "    # add subset node to graph\n",
    "    graph.add_node(subset, \"Subset\", \"Read\")\n",
    "    \n",
    "    # write it back to the dictionary\n",
    "    data_sources[data_source][\"graph\"] = graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets look again at our graph, and check what has been added at the bottom;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_sources[\"L2\"][\"graph\"].nice_view()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that we now have a Subset node that includes the WKT that we specified at the top of this notebook.\n",
    "\n",
    "There are two other important things to note. Firstly, that the addition of the Subset node now connects the Read node to the BandMatchs nodes via their source products. Secondly, that the Read and Write nodes have placeholder string in them (`$img1` and `$output`), which we use in eocanvas to connect the graph to our Sentinel-3 OLCI products, as supplied by the HDA, and our eventual download.\n",
    "\n",
    "Our graph is now ready, so lets launch it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_source = \"L2\"\n",
    "\n",
    "for url, product_name in zip(data_sources[data_source][\"urls\"], data_sources[data_source][\"product_names\"]):\n",
    "    inputs = Input(key=\"img1\", url=url)\n",
    "    config = Config(key=\"img1\", options=ConfigOption(uncompress=True, sub_path=\"xfdumanifest.xml\"))\n",
    "    process = SnapProcess(snap_graph=data_sources[data_source][\"graph\"], eo_config=config, eo_input=inputs)\n",
    "    process.prepare_inputs()\n",
    "\n",
    "    job = process.submit()\n",
    "    process.run(job, download_dir=download_dir)\n",
    "\n",
    "    # rename output  \n",
    "    downloaded_file = os.path.join(download_dir, os.path.basename(job.results[0].title))\n",
    "    output_file = os.path.join(download_dir, product_name.replace(\".SEN3\", \"_eocanvas_processed.nc\"))\n",
    "    os.rename(downloaded_file, output_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\" role=\"alert\">\n",
    "\n",
    "## <a id='section4'></a>4. Building data cubes\n",
    "[Back to top](#TOCTOP)\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No we have processed some of our data using `eocanvas` we can construct a data cube from it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bring to a common grid\n",
    "resolution = 0.003\n",
    "new_lons = np.arange(bbox[0], bbox[1] + resolution, resolution)\n",
    "new_lats = np.arange(bbox[2], bbox[3] + resolution, resolution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = glob.glob(os.path.join(download_dir, f\"*WFR____*\"))\n",
    "files_sorted = sorted(files, key=extract_first_date)\n",
    "\n",
    "ds_all = []\n",
    "for file in files_sorted:\n",
    "    print(file)\n",
    "\n",
    "    ds = xr.open_dataset(file)\n",
    "    T = datetime.datetime.strptime(os.path.basename(file).split(\"_\")[7], \"%Y%m%dT%H%M%S\")\n",
    "    T = pd.to_datetime([T]).to_numpy(dtype='datetime64[ns]')\n",
    "    ds = ds.expand_dims({\"time\": T})\n",
    "    ds = ds.interp(lon=new_lons, lat=new_lats, method=\"linear\")\n",
    "    ds_all.append(ds)\n",
    "\n",
    "cube = xr.concat(ds_all, dim=\"time\")\n",
    "cube = cube.chunk({\"time\": 1})\n",
    "\n",
    "for CHL_var in [\"Filtered_CHL_NN\", \"Filtered_CHL_OC4ME\", \"Filtered_CHL_MPH\"]:\n",
    "    try:\n",
    "        cube[CHL_var].attrs[\"units\"] = \"mg.m-3\"\n",
    "    except:\n",
    "        pass\n",
    "        \n",
    "cube.to_zarr(f\"OLCI_L2_CHL_cube.zarr\", mode=\"w\", consolidated=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\" role=\"alert\">\n",
    "\n",
    "## <a id='section5'></a>5. Comparing chlorophyll estimates using `xcube`\n",
    "\n",
    "[Back to top](#TOCTOP)\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets open our cube using xarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "WFR_cube = xr.open_zarr(\"OLCI_L2_CHL_cube.zarr\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can configure our xcube viewer to display this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "404 GET /viewer/config/config.json (127.0.0.1): xcube viewer has not been been configured\n",
      "404 GET /viewer/config/config.json (127.0.0.1) 3.30ms\n",
      "404 GET /viewer/config/config.json (127.0.0.1): xcube viewer has not been been configured\n",
      "404 GET /viewer/config/config.json (127.0.0.1) 1.69ms\n"
     ]
    }
   ],
   "source": [
    "viewer = Viewer(\n",
    "    server_config={\n",
    "        \"Styles\": [\n",
    "            {\n",
    "                \"Identifier\": \"CHL\",\n",
    "                \"ColorMappings\": {\n",
    "                    \"Filtered_CHL_NN\": {\"ValueRange\": [0.0, 20.0], \"ColorBar\": \"viridis\"},\n",
    "                    \"Filtered_CHL_OC4ME\": {\"ValueRange\": [0.0, 20.0], \"ColorBar\": \"viridis\"},\n",
    "                    \"Filtered_CHL_MPH\": {\"ValueRange\": [0.0, 20.0], \"ColorBar\": \"viridis\"},\n",
    "                    \"CHL\": {\"ValueRange\": [0, 20.0], \"ColorBar\": \"viridis\"}\n",
    "                },\n",
    "            }        \n",
    "        ]\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Server: http://localhost:8000\n",
      "Viewer: http://localhost:8000/viewer/?serverUrl=http://localhost:8000\n"
     ]
    }
   ],
   "source": [
    "viewer.add_dataset(WFR_cube, title=\"L2 CHL Test\", style=\"CHL\")\n",
    "viewer.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prior to this tutorial, we prepared two much larger data cubes that span the whole month of July 2022. One of these cubes uses an graph identical to the one shown above above for the CHL_NN and CHL_OC4ME products available at in the OLCI level-2 products. The other cube runs the L1B graph, also included in SNAP_Graphs folder to derive the MPH chlorophyll product. These two cubes are hosted on WEkEO S3 storage, and can be added directly to our xcube viewer. Both cubes were generated using exactly the same approach as described above. This workflow will work from any S3 storage.\n",
    "\n",
    "Lets connect to these remote cubes..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_L2 = xr.open_zarr(\n",
    "    \"s3://wekeo/egu2025/OLCI_L2_CHL_cube.zarr\",\n",
    "    consolidated=True,\n",
    "    storage_options={\"anon\" : True,\n",
    "        \"client_kwargs\": {\n",
    "            \"endpoint_url\": \"https://s3.waw3-2.cloudferro.com\"\n",
    "        }\n",
    "    }\n",
    ")\n",
    "\n",
    "ds_L1 = xr.open_zarr(\n",
    "    \"s3://wekeo/egu2025/OLCI_L1_CHL_cube.zarr\",\n",
    "    consolidated=True,\n",
    "    storage_options={\"anon\" : True,\n",
    "        \"client_kwargs\": {\n",
    "            \"endpoint_url\": \"https://s3.waw3-2.cloudferro.com\"\n",
    "        }\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "..and add them to our viewer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Server: http://localhost:8000\n",
      "Viewer: http://localhost:8000/viewer/?serverUrl=http://localhost:8000\n"
     ]
    }
   ],
   "source": [
    "viewer.add_dataset(ds_L2, title=\"L2 CHL Cube\", style=\"CHL\")\n",
    "viewer.add_dataset(ds_L1, title=\"L1 CHL Cube\", style=\"CHL\")\n",
    "viewer.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">> Compare the views for: 2022-07-03 09:31:00"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\" role=\"alert\">\n",
    "\n",
    "## <a id='section6'></a>6. Exploring level-3 ocean Baltic colour products from the Copernicus Marine Service\n",
    "[Back to top](#TOCTOP)\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To generate a long time series of ocean colour measurements requires combining data from multiple satellite missions, and applying algorithms that are suitable for this, taking in to account the different spectral configurations etc of the missions. For example, above we apply the MPH which only uses wavebands available on Sentinel-3 OLCI, and the historical MERIS mission. This limits it's suitability for application to long time series. Further it is designed for focusing on blooms, and doesn't account for other forms of variability which are present in the Baltic sea.\n",
    "\n",
    "As an optimal approach, we will access data from the Copernicus marine service where a regionally trained neural network using multiple algorithmic approaches is applied to multiyear records of ocean colour [[3]](#ref3). We will access data from the Copernicus Marine Service using the Copernicus Marine API. This loads data directly into memory, without the need to write anythin to a file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "\n",
    "### Accessing Copernicus Marine Service products\n",
    "\n",
    "To retrieve the data, we need will use the <a href=\"https://help.marine.copernicus.eu/en/articles/7949409-copernicus-marine-toolbox-introduction\" target=\"_blank\">Copernicus Marine API</a>. This allows us to remotely subset the data and read it directly into memory, for immediate use. If you are working with the recommended Anaconda Python distribution and used the environment file included in this repository (environment.yml) to build this python environment (as detailed in the README), you will already have installed this. If not, you can install the toolkit using;\n",
    "\n",
    "`conda install -c conda-forge copernicusmarine`\n",
    "\n",
    "To download data using the Copernicus Marine API, you need to provide credentials. To obtain these, you should register at the <a href=\"https://data.marine.copernicus.eu/register\" target=\"_blank\">Copernicus Marine Service</a> for an account and take note of you `username` and `password`. If you do not already have a local credentials file, you will be prompted to enter your credentials when you run the cell below. This will create the required local credentials file, so that you only need to run this once.\n",
    "\n",
    "*Note: For more information on authentication options please see this <a href=\"https://help.marine.copernicus.eu/en/articles/8185007-copernicus-marine-toolbox-credentials-configuration\" target=\"_blank\">web article</a>.*\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default location expected by the copernicusmarine package\n",
    "copernicus_marine_credentials_file = Path(Path.home() / '.copernicusmarine' / '.copernicusmarine-credentials')\n",
    "\n",
    "# Create it only if it does not already exists\n",
    "if not copernicus_marine_credentials_file.is_file():\n",
    "    copernicusmarine.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining our L3 search times\n",
    "start_oper_L3 = datetime.datetime(2022, 7, 1, 0, 0)\n",
    "end_oper_L3 = datetime.datetime(2022, 7, 31, 23, 59)\n",
    "\n",
    "start_clim_L3 = datetime.datetime(2017, 1, 1, 0, 0)\n",
    "end_clim_L3 = datetime.datetime(2024, 12, 31, 23, 59)\n",
    "\n",
    "CMEMS_product = \"cmems_obs-oc_bal_bgc-plankton_my_l3-multi-1km_P1D\"\n",
    "CMEMS_variables = ['CHL']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are authenticated, let's connect to our data set using the `open_dataset` method in the `copernicusmarine` toolkit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 2025-04-22T15:50:11Z - Dataset version was not specified, the latest one was selected: \"202411\"\n",
      "INFO - 2025-04-22T15:50:11Z - Dataset part was not specified, the first one was selected: \"default\"\n",
      "INFO - 2025-04-22T15:50:12Z - Service was not specified, the default one was selected: \"arco-geo-series\"\n"
     ]
    }
   ],
   "source": [
    "ds_L3 = copernicusmarine.open_dataset(\n",
    "               dataset_id=CMEMS_product,\n",
    "               variables=CMEMS_variables,\n",
    "               minimum_longitude=bbox[0],\n",
    "               maximum_longitude=bbox[2],\n",
    "               minimum_latitude=bbox[1],\n",
    "               maximum_latitude=bbox[3],\n",
    "               start_datetime=start_oper_L3.strftime(\"%Y-%m-%dT00:00:00.000Z\"),\n",
    "               end_datetime=end_oper_L3.strftime(\"%Y-%m-%dT23:59:59.000Z\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets now add our Dataset to the viewer, associating it with our defined *style*, and show the viewer. The viewer will open the latest \"time slice\" of the data set, but you can iterate it in time using the arrow buttons and click on any \"populated\" pixel to see a time series. You can also animate the whole time series using the \"play\" button.\n",
    "\n",
    "Explore the tool to see how the gridded CHL field changes in and around our bloom event."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Server: http://localhost:8000\n",
      "Viewer: http://localhost:8000/viewer/?serverUrl=http://localhost:8000\n"
     ]
    }
   ],
   "source": [
    "viewer.add_dataset(ds_L3, title=\"Baltic CHL\", style=\"CHL\")\n",
    "viewer.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\" role=\"alert\">\n",
    "\n",
    "## <a id='section7'></a>7. Downloading and analysing level-3 ocean colour products\n",
    "[Back to top](#TOCTOP)\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this final part of our analysis, we will download some data from the Copernicus Marine Service. Lets start by defining a file name (`output_filename`) our downloaded data, and cleat any existing file of the same name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_filename=os.path.join(download_dir, \"CMEMS_L3_BGC_CHL.nc\")\n",
    "if os.path.exists(output_filename):\n",
    "    os.remove(output_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To download data, rather than use the `open_dataset` option we used in the previous section, we use the `subset` method, which will write the data to our defeined output file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copernicusmarine.subset(\n",
    "               dataset_id=CMEMS_product,\n",
    "               variables=CMEMS_variables,\n",
    "               minimum_longitude=bbox[0],\n",
    "               maximum_longitude=bbox[2],\n",
    "               minimum_latitude=bbox[1],\n",
    "               maximum_latitude=bbox[3],\n",
    "               start_datetime=start_clim_L3.strftime(\"%Y-%m-%dT00:00:00.000Z\"),\n",
    "               end_datetime=end_clim_L3.strftime(\"%Y-%m-%dT23:59:59.000Z\"),\n",
    "               output_filename=output_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, lets process our downloaded data. We beginning by opening the relevant file..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_L3 = xr.open_mfdataset(output_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We don't want to take an area mean when the data is very sparse, so we will discard any time slice where we have less than \"`n_cut`\" points (n_cut by default is set to 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_cut = 10000\n",
    "ds_L3 = ds_L3.where(ds_L3[\"CHL\"].count(dim=[\"longitude\", \"latitude\"]) > n_cut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHL = np.log10(ds_L3[\"CHL\"].mean(dim=['latitude', 'longitude']).compute())\n",
    "time = ds_L3[\"time\"].compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, lets calculate a mean seasonal climatology so that we can compare our year of interest with the historical average."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLIM = CHL.groupby(\"time.dayofyear\").mean()\n",
    "CLIM = CLIM[ds_L3.time.dt.dayofyear - 1]\n",
    "ds_L3.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are ready to make our final plot..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(15, 7.5), dpi=150)\n",
    "plt.plot(time, CHL)\n",
    "plt.plot(time, CLIM, linestyle=\"--\")\n",
    "\n",
    "plots = []\n",
    "for CHL_average, col in zip(CHL_averages, [\"r\", \"#E67E22\", \"b\"]):\n",
    "    p1 = plt.scatter(datetime.datetime(2022, 7, 3), CHL_average, s=100, alpha=0.5, c=col,edgecolor=\"k\", zorder=100)\n",
    "    plots.append(p1)\n",
    "\n",
    "plt.legend(plots, [\"CHL: OC4ME\", \"CHL: NN\", \"CHL: MPH\"], frameon=False)\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Chlorophyll concentration [mg.m$^{-3}$]\");\n",
    "plt.xlim([datetime.datetime(2022, 1, 1), datetime.datetime(2022, 12, 31)])\n",
    "plt.xticks(rotation=45)\n",
    "ticks = [0, np.log10(3), 1, np.log10(30)]\n",
    "plt.ylim([min(ticks), max(ticks)])\n",
    "plt.yticks(ticks, [round(10**i) for i in ticks])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the time series of Chlorophyll-a concentration we can see a general seasonal cycle of elevated chlorophyll-a in the spring, followed by a decrease, and then a further elevation over the summer and early autumn. This can be observed in the data for 2022 (blue line), and the 10 year daily average climatology (dashed orange line). We can see that the two standard chlorophyll-a estimates are signficantly higher than the MPH, which agrees very closely with the estimate from the level-3 product. \n",
    "\n",
    "We can also observe the high level of variability around the average, seeing the spikes where the blue line deviates. However, how do we know if these are cyanobacteria blooms or not? Accurate chlorophyll-a estimation for cyanobacteria blooms is challenging, with a lack of insitu data, the complex optics of floating/submerged blooms, and further complications from the optical complexity of coastal ocean waters and atmospheres.\n",
    "\n",
    "In the publication by Brando et al. (2021) [[3]](#ref3) which underlies the Copernicus Marine Service data used above, a threshold technique was used to identify surface and subsurface blooms in both spring and summer, utilising the available remote sensing reflectance at 555nm and 670 nm in the underlying merged satellite data. This allowed for a more robust estimation of bloom patterns as a general indicator of eutrophication in the region.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\" role=\"alert\">\n",
    "\n",
    "## <a id='section8'></a>8. Conclusions\n",
    "[Back to top](#TOCTOP)\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we have seen that satellite data is capable of providing a detailed view of cyanobacteria bloom events. Modern sensors such as the OLCI sensors aboard the Sentinel-3 satellites can be exploted, thanks to their unique spectral bands, to develop specific algorithms for detection of blooms. Longer time series of ocean colour data are being developed to support the assessment of the role of blooms in eutrophication trends in regions such as the Baltic sea. As the time series of OLCI data lengthens, and new opportunities from hyperspectral missions are realised, further opportunities will arise to expand this work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Suggested next steps\n",
    "\n",
    "To further develop your skills and knowledge, and expand the application of this notebook you could try:\n",
    "* Applying the MPH algorithm in SNAP to a time series of OLCI images\n",
    "* Accessing the regional Baltic reflectance products from the Copernicus marine service, applying the thresholds to the values at 555 nm and 670 nm to identify blooms.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<a href=\"../../../Index.ipynb\" target=\"_blank\"><< Index</a>\n",
    "<hr>\n",
    "\n",
    "<a href=\"https://gitlab.eumetsat.int/eumetlab/ocean\" target=\"_blank\">View on GitLab</a> | <a href=\"https://training.eumetsat.int/\" target=\"_blank\">EUMETSAT Training</a> | <a href=mailto:ops@eumetsat.int target=\"_blank\">Contact helpdesk for support </a> | <a href=mailto:training@eumetsat.int target=\"_blank\">Contact our training team to collaborate on and reuse this material</a></span></p>"
   ]
  }
 ],
 "metadata": {
  "author": "Vinca Rosmorduc, Ben Loveday, Hayley Evers-King",
  "content_type": "Software & code",
  "data_access": [
   "Data Store",
   "CMEMS"
  ],
  "deployment": {
   "eumetsat": {
    "binder": {
     "link": "https://mybinder.org/v2/git/https%3A%2F%2Fgitlab.eumetsat.int%2Feumetlab%2Foceans%2Focean-training%2Fapplications%2Focean-case-studies/HEAD?labpath=Case_studies%2FWater_quality%2FAlgal_blooms%2FAlgal_blooms_baltic_2023.ipynb",
     "service_contact": "ops@eumetsat.int",
     "service_provider": "EUMETSAT"
    },
    "git": {
     "link": "https://gitlab.eumetsat.int/eumetlab/oceans/ocean-training/applications/ocean-case-studies/-/blob/main/Case_studies/Water_quality/Algal_blooms/Algal_blooms_baltic_2023.ipynb",
     "service_contact": "ops@eumetsat.int",
     "service_provider": "EUMETSAT"
    }
   },
   "wekeo": {
    "git": {
     "link": "https://github.com/wekeo/ocean-case-studies/blob/main/Case_studies/Water_quality/Algal_blooms/Algal_blooms_baltic_2023.ipynb",
     "service_contact": "ops@eumetsat.int",
     "service_provider": "EUMETSAT"
    },
    "url": {
     "link": "https://jupyterhub.prod.wekeo2.eu/hub/user-redirect/lab/tree/public/wekeo4oceans/ocean-case-studies/Case_studies/Water_quality/Algal_blooms/Algal_blooms_baltic_2023.ipynb",
     "service_contact": "ops@eumetsat.int",
     "service_provider": "EUMETSAT"
    }
   }
  },
  "description": "This Jupyter Notebook shows how Sentinel-3 OLCI and CMEMS products can be used to investigate Baltic cyanobacteria blooms.",
  "image": "../../../img/thumbs/Algal_blooms_baltic_2023_thumb.png",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  },
  "license": "MIT",
  "metadata_schema_version": "2.0.0",
  "originator": "EUMETSAT",
  "tags": {
   "data_provider": [
    "EUMETSAT",
    "CMEMS"
   ],
   "orbit": "LEO",
   "satellite": [
    "Sentinel-3",
    "Baltic Sea multiyear ocean colour"
   ],
   "sensor": [
    "OLCI (Sentinel-3)",
    "Multisensor"
   ],
   "service": "Ocean colour",
   "subtheme": [
    "Ocean biogeochemistry",
    "Water quality"
   ],
   "theme": "Marine",
   "variable": [
    "[Top-of-atmosphere radiance",
    "Water leaving reflectance",
    "Chlorophyll concentration",
    "Ocean colour"
   ]
  },
  "title": "Investigating cyanobacterial algal blooms in the Baltic Sea",
  "version": "2.0.0",
  "version_date": "2024-09-02"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
